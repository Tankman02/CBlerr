"""
üéâ –ü–∞—Ä—Å–µ—Ä (Recursive Descent Parser) –¥–ª—è —è–∑—ã–∫–∞ CBlerr
–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å–∫—É—á–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –≤ –∫—Ä–∞—Å–∏–≤–æ–µ –¥–µ—Ä–µ–≤–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ (AST)
–ü–æ—Ç–æ–º—É —á—Ç–æ —Ç–æ–∫–µ–Ω—ã - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –±–µ—Å–ø–æ—Ä—è–¥–æ–∫

–í–µ—Ä—Å–∏—è 4.0: OSDev & Low-Level Features
(—Ç.–µ. —Ç–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –ø–∏—Å–∞—Ç—å –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —Å–ª–æ–º–∞–µ—Ç –∫–æ–º–ø—å—é—Ç–µ—Ä)
"""
from typing import List, Optional
from core.lexer import Token, TokenType
from core.flux_ast import (
    Program, FunctionDef, Return, BinaryOp, Variable, Literal,
    IfStmt, Assign, Compare, Call, WhileLoop, BreakStmt, ContinueStmt,
    StructDef, FieldAccess, ArrayAccess, ArrayLiteral, LogicalOp,
    # v4.0: –Ω–æ–≤—ã–µ AST —É–∑–ª—ã
    PointerType, Dereference, InlineAsm, CastExpr, Decorator, ComptimeBlock,
    # v4.0: –º–æ–¥—É–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞
    ImportStmt, FromImportStmt, GlobalVariable
)


class Parser:
    """
    Recursive Descent Parser –¥–ª—è CBlerr
    (recursion - –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã –≤ –Ω–∞—á–∞–ª–µ 2000—Ö –∏ –ª—é–±–∏–º –≥—Ä–∏–º–∞—Å—ã)
    """
    
    def __init__(self, tokens: List[Token]):
        self.tokens = tokens
        self.pos = 0
    
    def current_token(self) -> Optional[Token]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω (–∏–ª–∏ None –µ—Å–ª–∏ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞ - –≥—Ä—É—Å—Ç–Ω–æ üò¢)"""
        if self.pos >= len(self.tokens):
            return None
        return self.tokens[self.pos]
    
    def peek_token(self, offset: int = 1) -> Optional[Token]:
        """–ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω –Ω–∞ offset –ø–æ–∑–∏—Ü–∏–π –≤–ø–µ—Ä–µ–¥"""
        pos = self.pos + offset
        if pos >= len(self.tokens):
            return None
        return self.tokens[pos]
    
    def parse_import(self) -> ImportStmt:
        """v4.0: –ü–∞—Ä—Å–∏—Ç: import module_name"""
        self.expect(TokenType.IMPORT, "–û–∂–∏–¥–∞–ª–æ—Å—å 'import'")
        
        module_name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –º–æ–¥—É–ª—è")
        module_name = module_name_token.value
        
        # import module as alias (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if self.current_token() and self.current_token().type == TokenType.AS:
            self.advance()
            alias_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è alias")
            # TODO: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å alias
        
        return ImportStmt(module_name)
    
    def parse_from_import(self) -> FromImportStmt:
        """v4.0: –ü–∞—Ä—Å–∏—Ç: from module import X, Y, Z"""
        self.expect(TokenType.FROM, "–û–∂–∏–¥–∞–ª–æ—Å—å 'from'")
        
        module_name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –º–æ–¥—É–ª—è")
        module_name = module_name_token.value
        
        self.expect(TokenType.IMPORT, "–û–∂–∏–¥–∞–ª–æ—Å—å 'import' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –º–æ–¥—É–ª—è")
        
        # –ü–∞—Ä—Å–∏–º —Å–ø–∏—Å–æ–∫ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º—ã—Ö –∏–º–µ–Ω
        items = []
        while True:
            name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞")
            items.append(name_token.value)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—è—Ç—É—é
            if self.current_token() and self.current_token().type == TokenType.COMMA:
                self.advance()
            else:
                break
        
        return FromImportStmt(module_name, items)
    
    def advance(self) -> Optional[Token]:
        """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω"""
        if self.pos < len(self.tokens):
            token = self.tokens[self.pos]
            self.pos += 1
            return token
        return None
    
    def expect(self, token_type: TokenType, error_msg: str = None, strict: bool = False):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Ç–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω –∏–º–µ–µ—Ç –æ–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø, –∏ –ø—Ä–æ–¥–≤–∏–≥–∞–µ—Ç—Å—è –≤–ø–µ—Ä–µ–¥
        
        Args:
            token_type: –æ–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø —Ç–æ–∫–µ–Ω–∞
            error_msg: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            strict: –µ—Å–ª–∏ True, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏ (—Å—Ç–∞—Ä–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
                   –µ—Å–ª–∏ False (default), –ø—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥
        """
        token = self.current_token()
        if not token or token.type != token_type:
            msg = error_msg or f"–û–∂–∏–¥–∞–ª—Å—è {token_type}, –ø–æ–ª—É—á–µ–Ω {token.type if token else 'EOF'}"
            if strict:
                raise SyntaxError(f"{msg} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line if token else '?'}")
            else:
                # –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º: –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                print(f"‚ö†Ô∏è  WARNING: {msg} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line if token else '?'}")
                # –ù–µ –ø—Ä–æ–¥–≤–∏–≥–∞–µ–º—Å—è, —á—Ç–æ–±—ã –ø–∞—Ä—Å–µ—Ä –º–æ–≥ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                return token
        return self.advance()
    
    def skip_newlines(self):
        """–ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã NEWLINE"""
        while self.current_token() and self.current_token().type == TokenType.NEWLINE:
            self.advance()
    
    def parse_decorators(self) -> List[Decorator]:
        """
        v4.2: –ü–∞—Ä—Å–∏—Ç –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã: @name –∏–ª–∏ @name(arg1, arg2, ...)
        
        ‚ú® –£–õ–£–ß–®–ï–ù–ò–Ø v4.2:
          - –ü—Ä–∏–Ω–∏–º–∞–µ—Ç COMPTIME, PACKED –∏ –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫–∞–∫ –≤–∞–ª–∏–¥–Ω—ã–µ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
          - –¢–∏—Ö–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã (–ª–æ–≥–∏—Ä—É–µ—Ç –≤ –ª–æ–≥, –Ω–µ –ø–∞–¥–∞–µ—Ç)
          - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
          - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥
        """
        decorators = []
        while self.current_token() and self.current_token().type == TokenType.AT:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º @
            
            token = self.current_token()
            if not token:
                # –¢–∏—Ö–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏
                print(f"‚ö†Ô∏è  WARNING: –û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ –ø–æ—Å–ª–µ @ –Ω–∞ —Å—Ç—Ä–æ–∫–µ {self.current_token().line if self.current_token() else '?'}")
                break
            
            # ‚ú® –ö–õ–Æ–ß–ï–í–û–ï –£–õ–£–ß–®–ï–ù–ò–ï: –ø—Ä–∏–Ω–∏–º–∞–µ–º –Ω–µ —Ç–æ–ª—å–∫–æ NAME, –Ω–æ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            if token.type == TokenType.NAME:
                dec_name = token.value
                self.advance()
            elif token.type in (TokenType.COMPTIME, TokenType.PACKED, TokenType.ASM, 
                               TokenType.INLINE, TokenType.EXTERN):
                # ‚ú® v4.2: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫–∞–∫ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
                dec_name = token.value
                self.advance()
            else:
                # ‚ú® v4.2: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä - –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º (–¢–ò–•–û)
                dec_name = token.value if hasattr(token, 'value') else f"unknown_{token.type.name}"
                if not dec_name.startswith('unknown_'):
                    print(f"‚ö†Ô∏è  WARNING: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä @{dec_name} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line}")
                self.advance()
            
            # –ê—Ä–≥—É–º–µ–Ω—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            dec_args = []
            if self.current_token() and self.current_token().type == TokenType.LPAREN:
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (
                if self.current_token() and self.current_token().type != TokenType.RPAREN:
                    while True:
                        arg_token = self.current_token()
                        if arg_token and arg_token.type == TokenType.NAME:
                            dec_args.append(arg_token.value)
                            self.advance()
                        else:
                            break
                        
                        if self.current_token() and self.current_token().type == TokenType.COMMA:
                            self.advance()
                        else:
                            break
                
                if self.current_token() and self.current_token().type == TokenType.RPAREN:
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º )
            
            decorators.append(Decorator(dec_name, dec_args if dec_args else None))
            self.skip_newlines()
        
        return decorators if decorators else None

    def parse_type(self) -> str:
        """
        –ß–∏—Ç–∞–µ—Ç –∏–º—è —Ç–∏–ø–∞: NAME, INT, STR –∏–ª–∏ v4.2:
          - ptr<Type> - –ø—Ä–æ—Å—Ç—ã–µ —É–∫–∞–∑–∞—Ç–µ–ª–∏
          - ptr<ptr<u8>> - –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —É–∫–∞–∑–∞—Ç–µ–ª–∏
          - u8, u16, u32, u64 - –±–µ–∑–∑–Ω–∞–∫–æ–≤—ã–µ —Ü–µ–ª—ã–µ
          - i8, i16, i32, i64 - –∑–Ω–∞–∫–æ–≤—ã–µ —Ü–µ–ª—ã–µ
          
        ‚ú® v4.2: –¢–∏—Ö–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ (–ª–æ–≥–∏—Ä—É–µ—Ç warning)
        """
        token = self.current_token()

        # New v5.0: support '*' pointer style (e.g. *i32, **void)
        if token and token.type == TokenType.MULTIPLY:
            star_count = 0
            while self.current_token() and self.current_token().type == TokenType.MULTIPLY:
                star_count += 1
                self.advance()

            base = self.parse_type()
            # wrap base in ptr<> star_count times
            for _ in range(star_count):
                base = f"ptr<{base}>"
            return base

        # v4.0: also accept ptr<...> legacy syntax
        if token and (token.type == TokenType.NAME and token.value == 'ptr' or
                      token.type == TokenType.LT):
            if token.type == TokenType.NAME and token.value == 'ptr':
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º 'ptr'
            
            if self.current_token() and self.current_token().type == TokenType.LT:
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º '<'
                base_type = self.parse_type()  # —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –≤—ã–∑–æ–≤ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å)
                
                if self.current_token() and self.current_token().type == TokenType.GT:
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º '>'
                    return f"ptr<{base_type}>"
                else:
                    print(f"‚ö†Ô∏è  WARNING: –û–∂–∏–¥–∞–ª–∞—Å—å '>' –ø–æ—Å–ª–µ —Ç–∏–ø–∞ –≤ ptr<> –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line}")
                    return f"ptr<{base_type}>"
        
        # v4.0: –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª
        if token and token.type in (TokenType.U8, TokenType.U16, TokenType.U32, TokenType.U64,
                                     TokenType.I8, TokenType.I16, TokenType.I32, TokenType.I64):
            type_name = token.value
            self.advance()
            return type_name
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–∏–ø—ã
        if token and token.type in (TokenType.NAME, TokenType.INT, TokenType.STR, 
                                    TokenType.BOOL, TokenType.FLOAT, TokenType.VOID):
            self.advance()
            return token.value
        
        # ‚ú® v4.2: –¢–∏—Ö–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ - –ª–æ–≥–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø
        if token:
            print(f"‚ö†Ô∏è  WARNING: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø {token.value} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line}")
            self.advance()
            return token.value if hasattr(token, 'value') else "unknown"
        
        raise SyntaxError(
            f"–û–∂–∏–¥–∞–ª—Å—è —Ç–∏–ø –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line if token else '?'}"
        )
    
    def parse_global_var(self) -> GlobalVariable:
        """–ü–∞—Ä—Å–∏—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é: const name: type = value –∏–ª–∏ name: type = value"""
        is_const = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º const
        if self.current_token().type == TokenType.CONST:
            is_const = True
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º const
        
        # name
        name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
        name = name_token.value
        
        # : type
        self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
        var_type = self.parse_type()
        
        # = value (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        value = None
        if self.current_token().type == TokenType.ASSIGN:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º =
            value = self.parse_expression()
        
        self.skip_newlines()
        
        return GlobalVariable(name, var_type, value, is_const)
    
    def parse(self) -> Program:
        """–ü–∞—Ä—Å–∏—Ç –ø—Ä–æ–≥—Ä–∞–º–º—É (–∫–æ—Ä–Ω–µ–≤–æ–π –º–µ—Ç–æ–¥)"""
        functions = []
        structs = []
        imports = []
        global_vars = []
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        self.skip_newlines()
        
        # v4.0: –ü–∞—Ä—Å–∏–º –∏–º–ø–æ—Ä—Ç—ã –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
        while self.current_token() and self.current_token().type in (TokenType.IMPORT, TokenType.FROM):
            if self.current_token().type == TokenType.IMPORT:
                import_stmt = self.parse_import()
                imports.append(import_stmt)
            elif self.current_token().type == TokenType.FROM:
                from_import_stmt = self.parse_from_import()
                imports.append(from_import_stmt)
            
            self.skip_newlines()
        
        # –ü–∞—Ä—Å–∏–º —Ñ—É–Ω–∫—Ü–∏–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –±–ª–æ–∫–∏ comptime –¥–æ –∫–æ–Ω—Ü–∞ —Ñ–∞–π–ª–∞
        while self.current_token() and self.current_token().type != TokenType.EOF:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º NEWLINE –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
            if self.current_token().type == TokenType.NEWLINE:
                self.skip_newlines()
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º DEDENT (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞)
            if self.current_token().type == TokenType.DEDENT:
                self.advance()
                continue

            # v4.0: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ comptime –±–ª–æ–∫
            if self.current_token().type == TokenType.COMPTIME:
                comptime_block = self.parse_comptime()
                # –í –ø—Ä–æ–≥—Ä–∞–º–º–µ –≤—ã–ø–æ–ª–Ω—è–µ–º comptime –±–ª–æ–∫ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                # (—Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–µ)
                continue
            
            # v4.0: –ü–∞—Ä—Å–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã (—Ç–æ–ª—å–∫–æ const —è–≤–Ω–æ)
            if self.current_token().type == TokenType.CONST:
                global_var = self.parse_global_var()
                global_vars.append(global_var)
                continue
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–±–µ–∑ const): name: type = value
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –Ω–∞—á–∞–ª–µ: NAME : TYPE ASSIGN
            # –≠—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ, —Ç.–∫. —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å DEF/EXTERN, –∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å STRUCT
            if self.current_token().type == TokenType.NAME and self.peek_token(1) and self.peek_token(1).type == TokenType.COLON:
                # –ò–º–µ–µ—Ç —Ñ–æ—Ä–º–∞—Ç name:..., –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —ç—Ç–æ –ª–∏ —Ñ—É–Ω–∫—Ü–∏—è
                # –§—É–Ω–∫—Ü–∏–∏ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å def/extern –∏–ª–∏ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ñ—É–Ω–∫—Ü–∏–µ–π
                # –°—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å struct –∏–ª–∏ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞ 
                # –ó–Ω–∞—á–∏—Ç, —ç—Ç–æ –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è!
                saved_pos = self.pos
                try:
                    name_token = self.current_token()
                    name = name_token.value
                    self.advance()
                    self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':'")
                    var_type = self.parse_type()
                    
                    value = None
                    if self.current_token() and self.current_token().type == TokenType.ASSIGN:
                        self.advance()
                        value = self.parse_expression()
                    
                    self.skip_newlines()
                    global_vars.append(GlobalVariable(name, var_type, value, is_const=False))
                    continue
                except Exception as e:
                    # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º—Å—è
                    self.pos = saved_pos
            
            # v4.0: –ü–∞—Ä—Å–∏–º –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã –ø–µ—Ä–µ–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏–µ–π
            decorators = self.parse_decorators()
            
            if self.current_token().type == TokenType.STRUCT:
                # –ü–∞—Ä—Å–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                struct = self.parse_struct_def(decorators)
                structs.append(struct)
            elif self.current_token().type in (TokenType.DEF, TokenType.EXTERN):
                func = self.parse_function(decorators)
                functions.append(func)
            else:
                raise SyntaxError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω {self.current_token().type} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {self.current_token().line}")
        
        # v4.0: –í–æ–∑–≤—Ä–∞—â–∞–µ–º Program —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏ –∏ –≥–ª–æ–±–∞–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
        program = Program(
            imports=imports if imports else [],
            global_vars=global_vars if global_vars else [],
            functions=functions if functions else [],
            structs=structs if structs else []
        )
        return program
    def parse_function(self, decorators: List[Decorator] = None) -> FunctionDef:
        """–ü–∞—Ä—Å–∏—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏: [extern] def name(params) [->] return_type: body"""
        # extern (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        is_extern = False
        if self.current_token().type == TokenType.EXTERN:
            is_extern = True
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º extern
        
        # def
        self.expect(TokenType.DEF, "–û–∂–∏–¥–∞–ª–æ—Å—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 'def'")
        
        # name
        name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏")
        name = name_token.value
        
        # (
        self.expect(TokenType.LPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å '(' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏")
        
        # params: —Å–ø–∏—Å–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π varargs)
        params = []
        is_vararg = False  # ‚ú® –ù–û–í–û–ï: —Ñ–ª–∞–≥ –¥–ª—è varargs
        
        if self.current_token().type != TokenType.RPAREN:
            # –ï—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä
            while True:
                # ‚ú® –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ varargs (...)
                if self.current_token() and self.current_token().type == TokenType.ELLIPSIS:
                    is_vararg = True
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ...
                    break
                
                # param_name: type
                # Note: –ø–∞—Ä–∞–º–µ—Ç—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–º–µ–Ω–µ–º, –Ω–æ —Ç–∞–∫–∂–µ –∏ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º —Ç–∏–ø–∞ (str, int, etc.)
                param_name_token = self.current_token()
                
                # –†–∞–∑—Ä–µ—à–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–∫–µ–Ω—ã –∫–∞–∫ –∏–º–µ–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                if param_name_token and param_name_token.type in (TokenType.NAME, TokenType.STR, TokenType.INT, 
                                                                    TokenType.BOOL, TokenType.FLOAT,
                                                                    TokenType.U8, TokenType.U16, TokenType.U32, TokenType.U64,
                                                                    TokenType.I8, TokenType.I16, TokenType.I32, TokenType.I64):
                    param_name = param_name_token.value
                    self.advance()
                else:
                    raise SyntaxError(f"–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–µ {param_name_token.line if param_name_token else '?'}")
                
                self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
                
                param_type = self.parse_type()
                
                params.append((param_name, param_type))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–º–æ–∂–µ—Ç –±—ã—Ç—å varargs)
                if self.current_token() and self.current_token().type == TokenType.COMMA:
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø—è—Ç—É—é
                else:
                    break
        
        # )
        self.expect(TokenType.RPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å ')' –ø–æ—Å–ª–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        
        # -> return_type (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ return_type
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞:
        # - def f() -> int:
        # - extern def f() int
        return_type = None
        if self.current_token().type == TokenType.ARROW:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ->
            return_type = self.parse_type()
        elif self.current_token().type != TokenType.COLON and self.current_token().type != TokenType.EOF and not self._is_keyword_or_dedent():
            # –ï—Å–ª–∏ –Ω–µ—Ç ARROW –∏ –Ω–µ –¥–≤–æ–µ—Ç–æ—á–∏–µ, –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ç–∏–ø (C-style —Å–∏–Ω—Ç–∞–∫—Å–∏—Å)
            return_type = self.parse_type()
        
        # –î–ª—è extern —Ñ—É–Ω–∫—Ü–∏–π —Ç–µ–ª–∞ –Ω–µ—Ç, –¥–≤–æ–µ—Ç–æ—á–∏–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        if is_extern:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–≤–æ–µ—Ç–æ—á–∏–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Ç–æ–∂–µ –æ–∫
            if self.current_token() and self.current_token().type == TokenType.COLON:
                self.advance()
            self.skip_newlines()
            func_def = FunctionDef(name, params, return_type, [], is_extern=True, is_vararg=is_vararg)
            func_def.decorators = decorators
            return func_def

        # : (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π)
        self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã —Ñ—É–Ω–∫—Ü–∏–∏")
        
        # body: —Å–ø–∏—Å–æ–∫ statements (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤)
        self.skip_newlines()

        # –û–∂–∏–¥–∞–µ–º INDENT
        body = []
        if self.current_token() and self.current_token().type == TokenType.INDENT:
            self.advance()
            # –ü–∞—Ä—Å–∏–º statements –¥–æ DEDENT
            while True:
                self.skip_newlines()
                token = self.current_token()
                if not token or token.type == TokenType.EOF:
                    break
                if token.type == TokenType.DEDENT:
                    self.advance()
                    break
                stmt = self.parse_statement()
                if stmt:
                    body.append(stmt)
        else:
            # –¢–µ–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É (–Ω–µ—á–∞—Å—Ç—ã–π —Å–ª—É—á–∞–π) ‚Äî –ø–∞—Ä—Å–∏–º single statement
            stmt = self.parse_statement()
            if stmt:
                body.append(stmt)

        func_def = FunctionDef(name, params, return_type, body, is_extern=False, is_vararg=is_vararg)
        func_def.decorators = decorators
        return func_def

    def parse_statement(self):
        """–ü–∞—Ä—Å–∏—Ç statement (–æ–ø–µ—Ä–∞—Ç–æ—Ä)"""
        token = self.current_token()
        if not token:
            return None

        # v4.0: asm() –±–ª–æ–∫
        if token.type == TokenType.ASM:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º 'asm'
            self.expect(TokenType.LPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å '(' –ø–æ—Å–ª–µ 'asm'")

            # Asm –∫–æ–¥ –≤ —Å—Ç—Ä–æ–∫–µ
            asm_token = self.expect(TokenType.STRING, "–û–∂–∏–¥–∞–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞ —Å asm –∫–æ–¥–æ–º")
            asm_code = asm_token.value

            self.expect(TokenType.RPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å ')' –ø–æ—Å–ª–µ asm –∫–æ–¥–∞")
            return InlineAsm(asm_code)

        if token.type == TokenType.RETURN:
            return self.parse_return()
        elif token.type == TokenType.IF:
            return self.parse_if_stmt()
        elif token.type == TokenType.WHILE:
            return self.parse_while_stmt()
        elif token.type == TokenType.BREAK:
            self.advance()
            return BreakStmt()
        elif token.type == TokenType.CONTINUE:
            self.advance()
            return ContinueStmt()
        elif token.type == TokenType.LET:
            # let name = expr
            self.advance()
            name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ—Å–ª–µ 'let'")
            name = name_token.value
            if self.current_token() and self.current_token().type == TokenType.ASSIGN:
                self.advance()
                value = self.parse_expression()
                return Assign(name, value)
            else:
                raise SyntaxError("–û–∂–∏–¥–∞–ª–æ—Å—å '=' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –≤ 'let' –æ–±—ä—è–≤–ª–µ–Ω–∏–∏")
        elif token.type == TokenType.NAME:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã:
            # 1. name: type = expr (–æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)
            # 2. name := expr (walrus)
            # 3. name = expr –∏–ª–∏ obj.field = expr (–ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ)
            # 4. –ü—Ä–æ—Å—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
            
            if self.peek_token() and self.peek_token().type == TokenType.COLON:
                return self.parse_var_decl()
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ —Å –¥–æ—Å—Ç—É–ø–æ–º
            # –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–Ω–∞–∫ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
            saved_pos = self.pos
            try:
                # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ª–µ–≤—É—é —á–∞—Å—Ç—å —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –ø–æ–ª—è–º
                left_expr = self.parse_atom_or_access_simple()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ
                if self.current_token() and self.current_token().type == TokenType.ASSIGN:
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º =
                    value = self.parse_expression()
                    if isinstance(left_expr, Variable):
                        return Assign(left_expr.name, value)
                    else:
                        return Assign(left_expr, value)
                elif self.current_token() and self.current_token().type == TokenType.WALRUS:
                    # name := expr (walrus)
                    if isinstance(left_expr, Variable):
                        self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º :=
                        value = self.parse_expression()
                        return Assign(left_expr.name, value)
                    else:
                        raise SyntaxError("–¢–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç :=")
                else:
                    # –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                    return left_expr
            except:
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–µ—Ä–Ω–µ–º—Å—è –∏ —Ä–∞—Å–ø–∞—Ä—Å–∏–º –∫–∞–∫ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                self.pos = saved_pos
                return self.parse_expression()
        else:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ
            # (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è *ptr = value)
            saved_pos = self.pos
            try:
                # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –ª–µ–≤–∞—è —á–∞—Å—Ç—å –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º parse_unary —á—Ç–æ–±—ã –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å *ptr, &var, –∏—Ç–¥.
                left_expr = self.parse_unary()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ
                if self.current_token() and self.current_token().type == TokenType.ASSIGN:
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º =
                    value = self.parse_expression()
                    if isinstance(left_expr, Variable):
                        return Assign(left_expr.name, value)
                    else:
                        return Assign(left_expr, value)
                else:
                    # –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                    return left_expr
            except:
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–µ—Ä–Ω–µ–º—Å—è –∏ —Ä–∞—Å–ø–∞—Ä—Å–∏–º –∫–∞–∫ –æ–±—ã—á–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                self.pos = saved_pos
                return self.parse_expression()
    
    def _is_keyword_or_dedent(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—É—â–∏–π —Ç–æ–∫–µ–Ω –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º –∏–ª–∏ DEDENT"""
        token = self.current_token()
        if not token:
            return True
        return token.type in (TokenType.DEDENT, TokenType.EOF, TokenType.NEWLINE)

    def parse_struct_def(self, decorators: List[Decorator] = None) -> StructDef:
        """–ü–∞—Ä—Å–∏—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: struct Name: field1: type1, field2: type2, ..."""
        # struct
        self.expect(TokenType.STRUCT, "–û–∂–∏–¥–∞–ª–æ—Å—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 'struct'")
        
        # name
        name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
        name = name_token.value
        
        # :
        self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
        
        # fields
        self.skip_newlines()
        
        # –û–∂–∏–¥–∞–µ–º INDENT
        if self.current_token().type == TokenType.INDENT:
            self.advance()
        else:
            raise SyntaxError("–û–∂–∏–¥–∞–ª—Å—è –æ—Ç—Å—Ç—É–ø –ø–æ—Å–ª–µ ':' –Ω–∞ —Å—Ç—Ä–æ–∫–µ struct")
        
        fields = []
        # –ü–∞—Ä—Å–∏–º –ø–æ–ª—è –¥–æ DEDENT
        while True:
            self.skip_newlines()
            token = self.current_token()
            if not token:
                break
            if token.type == TokenType.DEDENT:
                self.advance()
                break
            if token.type == TokenType.EOF:
                break
            
            # –ü–∞—Ä—Å–∏–º –ø–æ–ª–µ: name: type
            field_name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–æ–ª—è")
            field_name = field_name_token.value
            
            self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –ø–æ–ª—è")
            
            field_type = self.parse_type()
            
            fields.append((field_name, field_type))
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º NEWLINE –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è
            self.skip_newlines()
        
        struct_def = StructDef(name, fields)
        struct_def.decorators = decorators
        return struct_def
    
    def parse_comptime(self) -> ComptimeBlock:
        """v4.0: –ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ compile-time: comptime { ... }"""
        self.expect(TokenType.COMPTIME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 'comptime'")
        
        self.skip_newlines()
        
        # –ß–∏—Ç–∞–µ–º –∫–æ–¥ Python –¥–æ –∫–æ–Ω—Ü–∞ –±–ª–æ–∫–∞ (–º–µ–∂–¥—É { –∏ })
        code_lines = []
        
        if self.current_token().type == TokenType.INDENT:
            self.advance()
        
        while True:
            token = self.current_token()
            if not token or token.type == TokenType.EOF:
                break
            if token.type == TokenType.DEDENT:
                self.advance()
                break
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –∫–∞–∫ —Å—Ç—Ä–æ–∫—É (—É–ø—Ä–æ—â–µ–Ω–∏–µ)
            if token.type == TokenType.NEWLINE:
                code_lines.append('\n')
                self.advance()
            else:
                code_lines.append(token.value or str(token.type.value))
                self.advance()
        
        code = ''.join(code_lines)
        return ComptimeBlock(code)
        """–ü–∞—Ä—Å–∏—Ç statement (–æ–ø–µ—Ä–∞—Ç–æ—Ä)"""
        token = self.current_token()
        if not token:
            return None
        
        # v4.0: asm() –±–ª–æ–∫
        if token.type == TokenType.ASM:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º 'asm'
            self.expect(TokenType.LPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å '(' –ø–æ—Å–ª–µ 'asm'")
            
            # Asm –∫–æ–¥ –≤ —Å—Ç—Ä–æ–∫–µ
            asm_token = self.expect(TokenType.STRING, "–û–∂–∏–¥–∞–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞ —Å asm –∫–æ–¥–æ–º")
            asm_code = asm_token.value
            
            self.expect(TokenType.RPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å ')' –ø–æ—Å–ª–µ asm –∫–æ–¥–∞")
            return InlineAsm(asm_code)
        
        if token.type == TokenType.RETURN:
            return self.parse_return()
        elif token.type == TokenType.IF:
            return self.parse_if_stmt()
        elif token.type == TokenType.WHILE:  # while loop
            return self.parse_while_stmt()
        elif token.type == TokenType.BREAK:  # break statement
            self.advance()
            return BreakStmt()
        elif token.type == TokenType.CONTINUE:  # continue statement
            self.advance()
            return ContinueStmt()
        elif token.type == TokenType.NAME:
            # –ú–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ, –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏: –¥–≤–æ–µ—Ç–æ—á–∏–µ –∏–ª–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
            if self.peek_token() and self.peek_token().type == TokenType.COLON:
                # –û–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å —Ç–∏–ø–æ–º: name: type = expr
                return self.parse_var_decl()
            elif self.peek_token() and self.peek_token().type == TokenType.ASSIGN:
                # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ: name = expr
                return self.parse_assign()
            else:
                # –≠—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
                return self.parse_expression()
        else:
            # –í—ã—Ä–∞–∂–µ–Ω–∏–µ
            return self.parse_expression()
    
    def parse_return(self) -> Return:
        """–ü–∞—Ä—Å–∏—Ç –æ–ø–µ—Ä–∞—Ç–æ—Ä return"""
        self.expect(TokenType.RETURN, "–û–∂–∏–¥–∞–ª–æ—Å—å 'return'")
        
        # return –º–æ–∂–µ—Ç –±—ã—Ç—å —Å –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º –∏–ª–∏ –±–µ–∑
        if self.current_token() and self.current_token().type not in (TokenType.NEWLINE, TokenType.DEDENT, TokenType.EOF):
            value = self.parse_expression()
        else:
            value = None
        
        return Return(value)
    
    def parse_assign(self) -> Assign:
        """–ü–∞—Ä—Å–∏—Ç –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ: name = expression –∏–ª–∏ obj.field = expression –∏–ª–∏ arr[idx] = expression
        
        v4.3: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è –∫ –ø–æ–ª—è–º —Å—Ç—Ä—É–∫—Ç—É—Ä –∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º –º–∞—Å—Å–∏–≤–æ–≤
        """
        # –ü—Ä–æ—á–∏—Ç–∞–µ–º –ª–µ–≤—É—é —á–∞—Å—Ç—å –∫–∞–∫ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è, –ø–æ–ª–µ, —ç–ª–µ–º–µ–Ω—Ç –º–∞—Å—Å–∏–≤–∞)
        left_expr = self.parse_atom_or_access()
        
        # =
        self.expect(TokenType.ASSIGN, "–û–∂–∏–¥–∞–ª–æ—Å—å '=' –ø–æ—Å–ª–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ –ø–æ–ª—è")
        
        # –í—ã—Ä–∞–∂–µ–Ω–∏–µ —Å–ø—Ä–∞–≤–∞
        value = self.parse_expression()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏: –µ—Å–ª–∏ –ª–µ–≤–∞—è —á–∞—Å—Ç—å - –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
        if isinstance(left_expr, Variable):
            return Assign(left_expr.name, value)
        else:
            # –î–ª—è –ø–æ–ª–µ–π –∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –º–∞—Å—Å–∏–≤–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ
            # (—Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –≤ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–µ)
            return Assign(left_expr, value)
    
    def parse_atom_or_access_simple(self):
        """–ü–∞—Ä—Å–∏—Ç –∞—Ç–æ–º–∞—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ–ª—è–º –∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º
        
        v4.3: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è –∫ –ø–æ–ª—è–º —Å—Ç—Ä—É–∫—Ç—É—Ä
        """
        token = self.current_token()
        if not token or token.type != TokenType.NAME:
            raise SyntaxError(f"–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line if token else '?'}")
        
        name = token.value
        self.advance()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
        if self.current_token() and self.current_token().type == TokenType.LPAREN:
            expr = self.parse_call(name)
        else:
            expr = Variable(name)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–æ–ª—è–º –∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º
        while self.current_token():
            if self.current_token().type == TokenType.DOT:
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º .
                field_name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–æ–ª—è –ø–æ—Å–ª–µ '.'")
                expr = FieldAccess(expr, field_name_token.value)
            elif self.current_token().type == TokenType.LBRACKET:
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º [
                index = self.parse_expression()
                self.expect(TokenType.RBRACKET, "–û–∂–∏–¥–∞–ª–∞—Å—å ']'")
                expr = ArrayAccess(expr, index)
            else:
                break
        
        return expr
    
    def parse_atom_or_access(self):
        """–ê–ª–∏–∞—Å –¥–ª—è parse_atom_or_access_simple –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        return self.parse_atom_or_access_simple()
    
    def parse_var_decl(self) -> Assign:
        """–ü–∞—Ä—Å–∏—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: name: type = expression"""
        # name
        name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
        name = name_token.value
        
        # :
        self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
        
        # type (–∏—Å–ø–æ–ª—å–∑—É–µ–º parse_type —á—Ç–æ–±—ã –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å *i32)
        type_name = self.parse_type()
        
        # = (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if self.current_token() and self.current_token().type == TokenType.ASSIGN:
            self.advance()
            # –í—ã—Ä–∞–∂–µ–Ω–∏–µ
            value = self.parse_expression()
            return Assign(name, value, type_name)
        else:
            # –ü—Ä–æ—Å—Ç–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –±–µ–∑ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º Assign —Å –Ω—É–ª–µ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏ —É–∫–∞–∑–∞–Ω–Ω—ã–º —Ç–∏–ø–æ–º
            return Assign(name, Literal(0, 'int'), type_name)
    
    def parse_if_stmt(self) -> IfStmt:
        """–ü–∞—Ä—Å–∏—Ç —É—Å–ª–æ–≤–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä: if condition: ... else: ..."""
        # if
        self.expect(TokenType.IF, "–û–∂–∏–¥–∞–ª–æ—Å—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 'if'")
        
        # condition
        condition = self.parse_expression()
        
        # :
        self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ —É—Å–ª–æ–≤–∏—è")
        
        # then body: —Å–ø–∏—Å–æ–∫ statements (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤)
        self.skip_newlines()
        
        # –û–∂–∏–¥–∞–µ–º INDENT –¥–ª—è then –±–ª–æ–∫–∞
        if self.current_token().type == TokenType.INDENT:
            self.advance()
        else:
            # –¢–µ–ª–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ (–¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º)
            raise SyntaxError("–û–∂–∏–¥–∞–ª—Å—è –æ—Ç—Å—Ç—É–ø –ø–æ—Å–ª–µ ':' –Ω–∞ —Å—Ç—Ä–æ–∫–µ if")
        
        then_body = []
        # –ü–∞—Ä—Å–∏–º statements –¥–æ DEDENT –∏–ª–∏ else
        while True:
            self.skip_newlines()
            token = self.current_token()
            if not token:
                break
            if token.type == TokenType.DEDENT:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º DEDENT –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–¥–µ—Ç –ª–∏ else
                self.advance()
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ NEWLINE –ø–æ—Å–ª–µ DEDENT
                self.skip_newlines()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ else –Ω–∞ —Ç–æ–º –∂–µ —É—Ä–æ–≤–Ω–µ
                if self.current_token() and self.current_token().type == TokenType.ELSE:
                    # –ï—Å—Ç—å else –±–ª–æ–∫
                    break
                # –ù–µ—Ç else, –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º
                break
            if token.type == TokenType.EOF:
                break
            
            stmt = self.parse_statement()
            if stmt:
                then_body.append(stmt)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ else
        else_body = None
        if self.current_token() and self.current_token().type == TokenType.ELSE:
            # else
            self.expect(TokenType.ELSE, "–û–∂–∏–¥–∞–ª–æ—Å—å 'else'")
            
            # :
            self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ 'else'")
            
            # else body: —Å–ø–∏—Å–æ–∫ statements (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤)
            self.skip_newlines()
            
            # –û–∂–∏–¥–∞–µ–º INDENT –¥–ª—è else –±–ª–æ–∫–∞
            if self.current_token().type == TokenType.INDENT:
                self.advance()
            else:
                raise SyntaxError("–û–∂–∏–¥–∞–ª—Å—è –æ—Ç—Å—Ç—É–ø –ø–æ—Å–ª–µ ':' –Ω–∞ —Å—Ç—Ä–æ–∫–µ else")
            
            else_body = []
            # –ü–∞—Ä—Å–∏–º statements –¥–æ DEDENT
            while True:
                self.skip_newlines()
                token = self.current_token()
                if not token:
                    break
                if token.type == TokenType.DEDENT:
                    self.advance()
                    break
                if token.type == TokenType.EOF:
                    break
                
                stmt = self.parse_statement()
                if stmt:
                    else_body.append(stmt)
        
        return IfStmt(condition, then_body, else_body)
    
    def parse_while_stmt(self) -> WhileLoop:
        """NEW: –ü–∞—Ä—Å–∏—Ç —Ü–∏–∫–ª while: while condition: body"""
        # while
        self.expect(TokenType.WHILE, "–û–∂–∏–¥–∞–ª–æ—Å—å –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ 'while'")
        
        # condition
        condition = self.parse_expression()
        
        # :
        self.expect(TokenType.COLON, "–û–∂–∏–¥–∞–ª–æ—Å—å ':' –ø–æ—Å–ª–µ —É—Å–ª–æ–≤–∏—è")
        
        # body: —Å–ø–∏—Å–æ–∫ statements (—Å —É—á–µ—Ç–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤)
        self.skip_newlines()
        
        # –û–∂–∏–¥–∞–µ–º INDENT
        if self.current_token().type == TokenType.INDENT:
            self.advance()
        else:
            raise SyntaxError("–û–∂–∏–¥–∞–ª—Å—è –æ—Ç—Å—Ç—É–ø –ø–æ—Å–ª–µ ':' –Ω–∞ —Å—Ç—Ä–æ–∫–µ while")
        
        body = []
        # –ü–∞—Ä—Å–∏–º statements –¥–æ DEDENT
        while True:
            self.skip_newlines()
            token = self.current_token()
            if not token:
                break
            if token.type == TokenType.DEDENT:
                self.advance()
                break
            if token.type == TokenType.EOF:
                break
            
            stmt = self.parse_statement()
            if stmt:
                body.append(stmt)
        
        return WhileLoop(condition, body)
    
    def parse_expression(self):
        """–ü–∞—Ä—Å–∏—Ç –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (—Å —É—á–µ—Ç–æ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤)"""
        # –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (or) –∏–º–µ—é—Ç —Å–∞–º—ã–π –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        return self.parse_logical_or()
    
    def parse_logical_or(self):
        """NEW: –ü–∞—Ä—Å–∏—Ç –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ 'or'"""
        left = self.parse_logical_and()
        
        while self.current_token() and self.current_token().type == TokenType.OR:
            op_token = self.advance()
            right = self.parse_logical_and()
            left = LogicalOp('or', left, right)
        
        return left
    
    def parse_logical_and(self):
        """NEW: –ü–∞—Ä—Å–∏—Ç –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ 'and'"""
        left = self.parse_logical_not()
        
        while self.current_token() and self.current_token().type == TokenType.AND:
            op_token = self.advance()
            right = self.parse_logical_not()
            left = LogicalOp('and', left, right)
        
        return left
    
    def parse_logical_not(self):
        """NEW: –ü–∞—Ä—Å–∏—Ç —É–Ω–∞—Ä–Ω—ã–π –ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä 'not'"""
        if self.current_token() and self.current_token().type == TokenType.NOT:
            self.advance()
            expr = self.parse_logical_not()
            return LogicalOp('not', expr)
        
        return self.parse_comparison()
    
    def parse_comparison(self):
        """–ü–∞—Ä—Å–∏—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (==, !=, <, >, <=, >=)"""
        left = self.parse_additive()
        
        # –û–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comparison_ops = (TokenType.EQ, TokenType.NE, TokenType.LT, TokenType.GT, TokenType.LE, TokenType.GE)
        
        while self.current_token() and self.current_token().type in comparison_ops:
            op_token = self.advance()
            right = self.parse_additive()
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–æ–∫–µ–Ω –≤ —Å—Ç—Ä–æ–∫—É –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
            op_map = {
                TokenType.EQ: '==',
                TokenType.NE: '!=',
                TokenType.LT: '<',
                TokenType.GT: '>',
                TokenType.LE: '<=',
                TokenType.GE: '>=',
            }
            left = Compare(op_map[op_token.type], left, right)
        
        return left
    
    def parse_additive(self):
        """–ü–∞—Ä—Å–∏—Ç –∞–¥–¥–∏—Ç–∏–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (+, -)"""
        left = self.parse_multiplicative()
        
        while self.current_token() and self.current_token().type in (TokenType.PLUS, TokenType.MINUS):
            op_token = self.advance()
            right = self.parse_multiplicative()
            left = BinaryOp(op_token.value, left, right)
        
        return left
    
    def parse_multiplicative(self):
        """–ü–∞—Ä—Å–∏—Ç –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (*, /)"""
        left = self.parse_unary()
        
        while self.current_token() and self.current_token().type in (TokenType.MULTIPLY, TokenType.DIVIDE):
            op_token = self.advance()
            right = self.parse_unary()
            left = BinaryOp(op_token.value, left, right)
        
        return left
    
    def parse_unary(self):
        """–ü–∞—Ä—Å–∏—Ç —É–Ω–∞—Ä–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∏ –∞—Ç–æ–º–∞—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
        token = self.current_token()
        
        # v4.0: –†–∞–∑—ã–º–µ–Ω–æ–≤–∞–Ω–∏–µ —É–∫–∞–∑–∞—Ç–µ–ª—è: *ptr
        if token and token.type == TokenType.MULTIPLY:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º *
            ptr_expr = self.parse_unary()
            return Dereference(ptr_expr)
        
        # v4.0: –ê–¥—Ä–µ—Å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: &var (—É–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ AMP)
        if token and token.type == TokenType.AMP:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º &
            var_expr = self.parse_unary()
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫ ptr<expr>
            # (—Ç–æ—á–Ω–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä–µ)
            return var_expr  # –£–ø—Ä–æ—â–µ–Ω–∏–µ: –ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        
        # v4.0: –£–Ω–∞—Ä–Ω—ã–π –º–∏–Ω—É—Å: -expr (–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ 0 - expr)
        if token and token.type == TokenType.MINUS:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º -
            expr = self.parse_unary()
            # –°–æ–∑–¥–∞–µ–º BinaryOp: 0 - expr
            return BinaryOp('-', Literal(0, 'int'), expr)
        
        return self.parse_atom()
    
    def parse_atom(self):
        """–ü–∞—Ä—Å–∏—Ç –∞—Ç–æ–º–∞—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (–ª–∏—Ç–µ—Ä–∞–ª, –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è, –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏, —Å–∫–æ–±–∫–∏)"""
        token = self.current_token()
        if not token:
            raise SyntaxError("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞")
        
        # –°—Ç—Ä–æ–∫–æ–≤—ã–π –ª–∏—Ç–µ—Ä–∞–ª
        if token.type == TokenType.STRING:
            self.advance()
            return Literal(token.value, 'str')
        
        # –ß–∏—Å–ª–æ
        if token.type == TokenType.NUMBER:
            self.advance()
            # Determine if it's int or float
            if '.' in token.value:
                return Literal(float(token.value), 'float')
            else:
                return Literal(int(token.value), 'int')
        
        # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –∏–ª–∏ –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏)
        if token.type == TokenType.NAME:
            name = token.value
            self.advance()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≤—ã–∑–æ–≤ –ª–∏ —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏
            if self.current_token() and self.current_token().type == TokenType.LPAREN:
                # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: func_name(arg1, arg2, ...)
                expr = self.parse_call(name)
            else:
                expr = Variable(name)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º field access (obj.field) –∏ array access (arr[index])
            while self.current_token():
                if self.current_token().type == TokenType.DOT:
                    # Field access: obj.field
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º .
                    field_name_token = self.expect(TokenType.NAME, "–û–∂–∏–¥–∞–ª–æ—Å—å –∏–º—è –ø–æ–ª—è –ø–æ—Å–ª–µ '.'")
                    expr = FieldAccess(expr, field_name_token.value)
                elif self.current_token().type == TokenType.LBRACKET:
                    # Array access or pointer deref: arr[index]
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º [
                    index = self.parse_expression()
                    self.expect(TokenType.RBRACKET, "–û–∂–∏–¥–∞–ª–∞—Å—å ']'")
                    expr = Dereference(expr, index)
                else:
                    break
            
            # v4.0: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–∞: expr as Type
            if self.current_token() and self.current_token().type == TokenType.AS:
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º 'as'
                target_type = self.parse_type()
                expr = CastExpr(expr, target_type)
            
            return expr
        
        # –°–∫–æ–±–∫–∏
        if token.type == TokenType.LPAREN:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (
            expr = self.parse_expression()
            self.expect(TokenType.RPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å ')'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ—Å–ª–µ —Å–∫–æ–±–æ–∫
            if self.current_token() and self.current_token().type == TokenType.AS:
                self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º 'as'
                target_type = self.parse_type()
                expr = CastExpr(expr, target_type)
            
            return expr
        
        # –ú–∞—Å—Å–∏–≤—ã [1, 2, 3]
        if token.type == TokenType.LBRACKET:
            self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º [
            elements = []
            if self.current_token().type != TokenType.RBRACKET:
                while True:
                    elem = self.parse_expression()
                    elements.append(elem)
                    if self.current_token().type == TokenType.COMMA:
                        self.advance()
                    else:
                        break
            self.expect(TokenType.RBRACKET, "–û–∂–∏–¥–∞–ª–∞—Å—å ']'")
            return ArrayLiteral(elements)
        
        raise SyntaxError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω {token.type} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {token.line}")
    
    def parse_call(self, func_name: str) -> Call:
        """–ü–∞—Ä—Å–∏—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: func_name(arg1, arg2, ...)"""
        # (
        self.expect(TokenType.LPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å '(' –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏")
        
        # args: —Å–ø–∏—Å–æ–∫ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        args = []
        if self.current_token() and self.current_token().type != TokenType.RPAREN:
            # –ï—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞—Ä–≥—É–º–µ–Ω—Ç
            while True:
                arg = self.parse_expression()
                args.append(arg)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
                if self.current_token() and self.current_token().type == TokenType.COMMA:
                    self.advance()  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø—è—Ç—É—é
                else:
                    break
        
        # )
        self.expect(TokenType.RPAREN, "–û–∂–∏–¥–∞–ª–∞—Å—å ')' –ø–æ—Å–ª–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤")
        
        return Call(func_name, args)


def parse(tokens: List[Token]) -> Program:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    parser = Parser(tokens)
    return parser.parse()

